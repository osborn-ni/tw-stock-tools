"""
å°ˆæ¡ˆåç¨±ï¼šå°ç£è‚¡å¸‚è‡ªå‹•åŒ–ç›£æ§ç³»çµ±
ç¨‹å¼åç¨±ï¼šfetch_single_stock_clean.py

ã€ç¨‹å¼ç›®çš„èˆ‡æ ¸å¿ƒé‚è¼¯èªªæ˜ã€‘ï¼š
1. æŠ“å– (Extract)ï¼š
   - åŒæ™‚å‘ FinMind è«‹æ±‚ 6 ç¨®æ•¸æ“šï¼šè‚¡åƒ¹ã€ç•¶æ²–ã€èè³‡èåˆ¸ã€å¤–è³‡æŒè‚¡ã€å€Ÿåˆ¸ã€ä¸‰å¤§æ³•äººè²·è³£ã€‚
   
2. æ¸…æ´—èˆ‡è½‰æ› (Transform) - é€™æ˜¯ç¨‹å¼æœ€è°æ˜çš„åœ°æ–¹ï¼š
   - ã€æ•¸æ“šå»å™ªã€‘ï¼šè‡ªå‹•åˆªé™¤å‚™è¨»æ¬„(note)ä¸­çš„ HTML æ¨™ç±¤æˆ–äº‚ç¢¼ï¼Œä¿æŒè³‡æ–™æ•´æ½”ã€‚
   - ã€å€Ÿåˆ¸åŠ ç¸½ã€‘ï¼šå€Ÿåˆ¸ API å›å‚³çš„æ˜¯æ˜ç´°ï¼Œç¨‹å¼æœƒè‡ªå‹•ã€ŒæŒ‰æ—¥æœŸã€åŠ ç¸½æ‰€æœ‰å¼µæ•¸ã€‚
   - ã€ä¸‰å¤§æ³•äººæ¨ç´è½‰æ›ã€‘ï¼šé€™æ˜¯é—œéµï¼API åŸå§‹å›å‚³æ˜¯ã€Œä¸€åˆ—ä¸€å€‹æ³•äººã€ã€‚
     æœ¬ç¨‹å¼æœƒï¼š
     A. è‡ªå‹•ç®—å‡ºã€Œè²·è³£è¶… (net)ã€ = è²·é€²è‚¡æ•¸ - è³£å‡ºè‚¡æ•¸ã€‚
     B. åŸ·è¡Œã€Œæ¨ç´åˆ†æ (Pivot)ã€ï¼ŒæŠŠæ³•äººçš„åå­—å¾ã€Œç›´çš„ã€è®Šã€Œæ©«çš„ã€ã€‚
     ä¾‹å¦‚ï¼šåŸæœ¬ä¸‰è¡Œè³‡æ–™(å¤–è³‡ã€æŠ•ä¿¡ã€è‡ªç‡Ÿå•†)ï¼Œæœƒåˆä½µæˆä¸€è¡Œï¼Œä¸¦æ–°å¢ã€Œå¤–è³‡_netã€ã€ã€ŒæŠ•ä¿¡_netã€æ¬„ä½ã€‚

3. åˆä½µèˆ‡å­˜æª” (Load)ï¼š
   - ä»¥ã€Œæ¯æ—¥è‚¡åƒ¹ã€ç‚ºåŸºåº•ï¼ŒæŠŠæ‰€æœ‰ç±Œç¢¼è³‡è¨Šã€Œæ©«å‘æ‹¼æ¥ã€ã€‚
   - å¦‚æœç•¶å¤©æ²’é–‹ç›¤(æˆäº¤é‡ç‚º0)ï¼Œæœƒè‡ªå‹•å‰”é™¤ï¼Œç¢ºä¿è³‡æ–™åˆ†ææ™‚ä¸æœƒæœ‰ç©ºæ´ã€‚
   - æœ€çµ‚æœƒç”¢å‡ºå„åˆ¥çš„æ¸…æ´—æª”ä»¥åŠä¸€å€‹ã€Œå¤§ç¸½è¡¨ (all_data)ã€ã€‚
"""

import pandas as pd
from FinMind.data import DataLoader
import os

def fetch_and_process(stock_id, start_date, end_date):
    dl = DataLoader()
    
    tasks = [
        (dl.taiwan_stock_daily, "daily", "è‚¡åƒ¹è³‡è¨Š"),
        (dl.taiwan_stock_day_trading, "day_trading", "ç•¶æ²–äº¤æ˜“"),
        (dl.taiwan_stock_margin_purchase_short_sale, "margin", "èè³‡èåˆ¸"),
        (dl.taiwan_stock_shareholding, "shareholding", "å¤–è³‡æŒè‚¡"),
        (dl.taiwan_stock_securities_lending, "lending", "å€Ÿåˆ¸æˆäº¤"),
        (dl.taiwan_stock_institutional_investors, "inst_investors", "ä¸‰å¤§æ³•äºº")
    ]

    clean_dfs = {}

    print(f"--- ğŸš€ å•Ÿå‹•ã€Œé€²éšæ¸…æ´—ä¸¦ä½µã€ä»»å‹™: {stock_id} ---")

    for api_func, suffix, label in tasks:
        try:
            df = api_func(stock_id=stock_id, start_date=start_date, end_date=end_date)
            
            if df is None or df.empty:
                print(f"âŒ {label:10}: ç„¡æ•¸æ“š")
                continue

            df['date'] = df['date'].astype(str)
            df['stock_id'] = df['stock_id'].astype(str)

            # --- ç‰¹å®šè¡¨æ¸…æ´—é‚è¼¯ ---
            
            # 1. å¤–è³‡æŒè‚¡ï¼šç§»é™¤ note 
            if suffix == "shareholding" and 'note' in df.columns:
                df = df.drop(columns=['note'])

            # 2. å€Ÿåˆ¸æˆäº¤ï¼šæŒ‰æ—¥åŠ ç¸½
            if suffix == "lending":
                q_col = next((c for c in ['volume', 'Quantity', 'quantity'] if c in df.columns), None)
                if q_col:
                    df = df.groupby(['date', 'stock_id'], as_index=False)[q_col].sum()
                    df.rename(columns={q_col: 'lending_total_vol'}, inplace=True)

            # 3. ä¸‰å¤§æ³•äººï¼šè¨ˆç®—è²·è³£è¶…ä¸¦é€²è¡Œæ¨ç´è½‰æ›
            if suffix == "inst_investors":
                # A. è¨ˆç®—è²·è³£è¶… (Net)
                df['net'] = df['buy'] - df['sell']
                
                # B. æ¨ç´åˆ†æï¼šå°‡ã€Œå¤–è³‡/æŠ•ä¿¡/è‡ªç‡Ÿå•†ã€è½‰ç‚ºæ©«å‘æ¬„ä½
                # é€™æ¨£åˆä½µæ™‚æ‰ä¸æœƒç”¢ç”Ÿå¤šé¤˜çš„åˆ—
                df = df.pivot_table(
                    index=['date', 'stock_id'], 
                    columns='name', 
                    values='net'
                ).reset_index()
                
                # C. é‡æ–°å‘½åæ¬„ä½ï¼ŒåŠ ä¸Šå¾Œç¶´æ–¹ä¾¿è­˜åˆ¥
                df.columns = [f"{c}_net" if c not in ['date', 'stock_id'] else c for c in df.columns]

            # å„²å­˜æ¸…æ´—å¾Œçš„æª”æ¡ˆ
            clean_filename = f"{stock_id}_{suffix}_clean.csv"
            df.to_csv(clean_filename, index=False, encoding='utf-8-sig')
            print(f"ğŸ’¾ {label:10}: å·²å­˜æª”")
            
            clean_dfs[suffix] = df
            
        except Exception as e:
            print(f"âš ï¸ {label:10}: éŒ¯èª¤ -> {e}")

    # --- åˆä½µç¸½è¡¨ ---
    if "daily" in clean_dfs:
        print(f"\n--- ğŸ”— æ­£åœ¨åˆä½µç²¾ç…‰ç¸½è¡¨ ---")
        all_data = clean_dfs["daily"]
        
        for key in [k for k in clean_dfs.keys() if k != "daily"]:
            all_data = pd.merge(all_data, clean_dfs[key], on=['date', 'stock_id'], how='left')

        if 'Trading_Volume' in all_data.columns:
            all_data = all_data[all_data['Trading_Volume'] > 0]
        
        final_output = f"{stock_id}_all_data.csv"
        all_data.to_csv(final_output, index=False, encoding='utf-8-sig')
        print(f"ğŸ‰ ä»»å‹™å®Œæˆï¼æœ€çµ‚ç­†æ•¸: {len(all_data)}")
    else:
        print("\nâŒ éŒ¯èª¤ï¼šç¼ºå°‘ daily è³‡æ–™")

if __name__ == "__main__":
    fetch_and_process("2330", "2010-01-01", "2025-12-31")